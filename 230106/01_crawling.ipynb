{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 크롤링\n",
    "1. 필수 라이브러리 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naver.com'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_data.find('네이버')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네이버'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_data[365:368]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beautifulsoup 라이브러리 설치\n",
    "1. html Tag의 데이터를 쉽게 추출하기 위한 라이브러리\n",
    "2. 웹의 구조를 어느 정도 인지를 한 상태에서 이 라이브러리 사용하면 쉽게 데이터 추출이 가능\n",
    "3. 파서(parser)를 활용해서 파이썬에서 접근이 쉽게 객체형태(변수)로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(html_data, 'html.parser')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태크명을 사용하여 검색\n",
    "    - 태그 : 해당 태그의 첫번째 정보를 출력\n",
    "    - 태그['속성'] : 해당 태그의 첫번째 속성에 대한 값을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>NAVER</title>\n",
      "title\n",
      "NAVER\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.name)\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"\" height=\"49\" src=\"https://static-whale.pstatic.net/main/img_darkmode_v12@2x.png\" style=\"padding-left: 100px\" width=\"200\"/>\n",
      "49\n",
      "https://static-whale.pstatic.net/main/img_darkmode_v12@2x.png\n"
     ]
    }
   ],
   "source": [
    "print(soup.img)\n",
    "print(soup.img['height'])\n",
    "print(soup.img['src'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find()\n",
    "    - HTML 안에서 해당 태그에 대한 첫번째 정보를 출력\n",
    "    - find(속성='값') : HTML 해당 속성과 일치하는 값에 대한 첫번째 정보를 출력\n",
    "- find_all()\n",
    "    - HTML 안에 해당 태그에 대한 모든 정보를 리스트 형식으로 출력\n",
    "    - limit 속성 : 리스트의 길이를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find(id = 'newsstand'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span>타임스퀘어 바로가기</span>\n"
     ]
    }
   ],
   "source": [
    "# print(soup.find_all('span'))\n",
    "# print(soup.find_all('span'), limit = 10)\n",
    "print(soup.find_all('span')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"blind\">NAVER whale</span>, <span class=\"blind\">쥬니어네이버</span>, <span class=\"blind\">해피빈</span>, <span class=\"blind\">검색</span>, <span class=\"blind\">한글 입력기</span>, <span class=\"blind\">자동완성 레이어</span>, <span class=\"blind\">쇼핑</span>, <span class=\"blind\">쇼핑LIVE</span>, <span class=\"blind\">리스트형</span>, <span class=\"blind\">썸네일형</span>, <span class=\"blind\">설정</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">닫기</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">재생</span>, <span class=\"blind\">재생</span>, <span class=\"blind\">재생</span>, <span class=\"blind\">재생</span>, <span class=\"blind\">재생</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">NAVER</span>, <span class=\"blind\">이전</span>, <span class=\"blind\">다음</span>, <span class=\"blind\">하락</span>, <span class=\"blind\">상승</span>, <span class=\"blind\">하락</span>, <span class=\"blind\"> <script id=\"veta_service_check\"></script> </span>, <span class=\"blind\">TOP</span>, <span class=\"blind\">라이트 모드로 보기</span>]\n"
     ]
    }
   ],
   "source": [
    "# 해당 태크에서 class 값을 기준으로 출력\n",
    "# print(soup.find_all('span', class_='blind'))\n",
    "print(soup.find_all('span', attrs={\n",
    "    'class' : 'blind'\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'뉴스스탠드 바로가기'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 태그를 제외하고 텍스트만 가지고 올때\n",
    "(soup.find('span')).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAVER whale', '쥬니어네이버', '해피빈', '검색', '한글 입력기', '자동완성 레이어', '쇼핑', '쇼핑LIVE', '리스트형', '썸네일형', '설정', '이전', '다음', '닫기', '닫기', '이전', '다음', '닫기', '닫기', '이전', '다음', '다음', '닫기', '닫기', '이전', '다음', '닫기', '닫기', '이전', '다음', '재생', '재생', '재생', '재생', '재생', '이전', '다음', 'NAVER', '이전', '다음', '하락', '상승', '하락', '  ', 'TOP', '라이트 모드로 보기']\n"
     ]
    }
   ],
   "source": [
    "span_list = soup.find_all('span', attrs={'class' : 'blind'})\n",
    "span_text = []\n",
    "for i in span_list:\n",
    "    span_text.append(i.get_text())\n",
    "print(span_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAVER whale', '쥬니어네이버', '해피빈', '검색', '한글 입력기', '자동완성 레이어', '쇼핑', '쇼핑LIVE', '리스트형', '썸네일형', '설정', '이전', '다음', '닫기', '닫기', '이전', '다음', '닫기', '닫기', '이전', '다음', '다음', '닫기', '닫기', '이전', '다음', '닫기', '닫기', '이전', '다음', '재생', '재생', '재생', '재생', '재생', '이전', '다음', 'NAVER', '이전', '다음', '하락', '상승', '하락', '  ', 'TOP', '라이트 모드로 보기']\n"
     ]
    }
   ],
   "source": [
    "# map 함수\n",
    "# map(함수, 리스트형태 데이터)\n",
    "def change(x):\n",
    "    return x.get_text()\n",
    "print(list(map(change, span_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAVER whale', '쥬니어네이버', '해피빈', '검색', '한글 입력기', '자동완성 레이어', '쇼핑', '쇼핑LIVE', '리스트형', '썸네일형', '설정', '이전', '다음', '닫기', '닫기', '이전', '다음', '닫기', '닫기', '이전', '다음', '다음', '닫기', '닫기', '이전', '다음', '닫기', '닫기', '이전', '다음', '재생', '재생', '재생', '재생', '재생', '이전', '다음', 'NAVER', '이전', '다음', '하락', '상승', '하락', '  ', 'TOP', '라이트 모드로 보기']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x : x.get_text(), span_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_one(), select() -> find(), find_all()과 같음\n",
    "print(soup.select_one('a'))\n",
    "print(soup.select('body a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.select('div > ul'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selenium 라이브러리\n",
    "1. 웹 어플리케이션 테스트를 위한 라이브러리\n",
    "2. python으로 웹 브라우저 제어하는 기능\n",
    "3. 웹 드라이버 별도의 프로그램 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seleniumNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading selenium-4.8.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 955.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "     -------------------------------------- 384.9/384.9 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\seopa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 1.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sortedcontainers, PySocks, outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 h11-0.14.0 outcome-1.2.0 selenium-4.8.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssjjk\\AppData\\Local\\Temp\\ipykernel_126724\\3668585491.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver= webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "# path는 webdriver의 경로 지정\n",
    "# 절대경로\n",
    "# windows\n",
    "# path = 'C:/Users/ssjjk/Downloads/chromedriver_win32/chromdriver.exe\n",
    "# mac\n",
    "# 상대경로\n",
    "path = '../webdriver/chromedriver.exe'\n",
    "driver= webdriver.Chrome(path)\n",
    "driver.get('https://www.naver.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = driver.find_element(By.ID, 'query')\n",
    "element.send_keys('구디 맛집')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(driver.page_source, 'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 class 생성\n",
    "1. 생성자 함수 처음 웹드라이버가 접속할 주소를 입력\n",
    "2. 새로운 함수 생성 - 검색어를 인자값으로 보내주면 웹드라이버에서 검색 후 검색한 페이지를 텍스트형태로 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Web():\n",
    "    # 생성자 함수에서는 입력한 주소 값만 저장\n",
    "    def __init__(self, _url):\n",
    "        self.url = _url\n",
    "    \n",
    "    # 검색함수에서는 1. 검색어를 인자로 받고 2. 웹드라이버를 실행 3. 검색창에 검색어를 입력하고 검색창 클릭 \n",
    "    # 4. 페이지 이동 후 페이지 html코드를 bs4 이용하여 객체화 한 데이터를 리턴\n",
    "    def search(self, _search):\n",
    "        self.path = '../webdriver/chromedriver'\n",
    "        self.driver = webdriver.Chrome(self.path)\n",
    "        time.sleep(1)\n",
    "        self.driver.get(self.url)\n",
    "        print(self.url)\n",
    "        # 1초 딜레이 생성\n",
    "        time.sleep(1)\n",
    "        self.element = self.driver.find_element(By.ID, 'query')\n",
    "        self.element.send_keys('_search')\n",
    "        self.element.send_keys(Keys.ENTER)\n",
    "        time.sleep(1)\n",
    "        self.result = bs(self.driver.page_source, 'html.parser')\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Web('https//www.naver.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.search('파싱 뜻')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f9024205cc48e5f62389b905109b1856dbfd744c4fe669d63a7eaa6f0de9f6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
